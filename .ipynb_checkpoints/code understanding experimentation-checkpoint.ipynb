{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 10\n",
    "c = 20\n",
    "TS = 1000\n",
    "feat_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "880\n",
      "970\n"
     ]
    }
   ],
   "source": [
    "batch_size = b\n",
    "train_size = 1000\n",
    "length = 1000\n",
    "nb_random_samples = 10\n",
    "# For each batch element, we pick nb_random_samples possible random\n",
    "# time series in the training set (choice of batches from where the\n",
    "# negative examples will be sampled)\n",
    "samples = numpy.random.choice(\n",
    "    train_size, size=(nb_random_samples, batch_size)\n",
    ")\n",
    "samples = torch.LongTensor(samples)\n",
    "print(samples.shape)\n",
    "\n",
    "# Choice of length of positive and negative samples\n",
    "length_pos_neg = numpy.random.randint(1, high=length + 1)\n",
    "print(length_pos_neg)\n",
    "\n",
    "# We choose for each batch example a random interval in the time\n",
    "# series, which is the 'anchor'\n",
    "random_length = numpy.random.randint(\n",
    "    length_pos_neg, high=length + 1\n",
    ")  # Length of anchors\n",
    "print(random_length)\n",
    "\n",
    "beginning_batches = numpy.random.randint(\n",
    "    0, high=length - random_length + 1, size=batch_size\n",
    ")  # Start of anchors\n",
    "\n",
    "print(\"Shape of begining batches is {}\".format(beginning_batches))\n",
    "# The positive samples are chosen at random in the chosen anchors\n",
    "beginning_samples_pos = numpy.random.randint(\n",
    "    0, high=random_length - length_pos_neg + 1, size=batch_size\n",
    ")  # Start of positive samples in the anchors\n",
    "# Start of positive samples in the batch examples\n",
    "beginning_positive = beginning_batches + beginning_samples_pos\n",
    "# End of positive samples in the batch examples\n",
    "end_positive = beginning_positive + length_pos_neg\n",
    "\n",
    "# We randomly choose nb_random_samples potential negative samples for\n",
    "# each batch example\n",
    "beginning_samples_neg = numpy.random.randint(\n",
    "    0, high=length - length_pos_neg + 1,\n",
    "    size=(nb_random_samples, batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btpenv] *",
   "language": "python",
   "name": "conda-env-btpenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
